
The lack of methods for tracking cells in 3D has been reported as a limiting factor, for instance in the context of immunoimaging (Cahalan and Parker, 2008). Despite the well-established protocol to capture microglia, innate immune cells in the central nervous system, in 3D using two-photon microscopy following the seminal works by Nimmerjahn et al. (2005) and Davalos et al. (2005), motility analysis has been performed by (and limited to) manual estimations derived from 2D projections (Davalos et al., 2008) in the numerous studies following these protocols. In fact, tracking microglia cells is complicated by several aspects. Microglia tightly contact specific brain structures in their resting state (Wake et al., 2009), often making it difficult to clearly separate them from their surroundingWhile the red cell remains in resting state, the green cell is activated through an induced injury and migrates along a trajectory (orange line, trajectory obtained by ct3d; blue line, trajectory obtained from manual annotation) toward a site of injury (purple dot); see Supplementary Video 1 for a rendered animation of the same data.
We implemented our algorithm in the publicly available ct3d software package, which is accompanied by the at3d graphical user interface. In terms of applying our algorithm, this article focuses on evaluating the performance of our cosegmentation-based approach for 3D cell tracking, leaving colocalization studies as a future direction. Cell tracking performance is evaluated both on two-photon live cell imaging data displaying zebrafish microglia in vivo, and on synthetically generated data that allow to determine the algorithm's accuracy based on the ground truth the synthetic data were generated from.
Filtering results: as for most segmentation and tracking approaches, the results obtained from the steps described above has a tendency toward overdetection, i.e. detecting segments that result from image noise rather than cells. To filter out those segments, we utilize life span filtering, i.e. we filter out all cells whose identity can be traced across less than a certain minimum number of frames. This cell filter, along with several other ways to eliminate cells with unsuitable size or volume features, follows corresponding features of the Celltrack software (Sacan et al., 2008) for 2D cell tracking; forct3d, they are implemented in the graphical user interface of the at3d tool shown in Figure 4.
• Alternative matching schemes: one class of cell tracking approaches is based on computing bipartite matchings between segmentations of individual time frames. As bipartite matchings may not capture events such as cell division or cell fusion, recent works such as Padfield et al. (2009) introduced alternative matching schemes that are more flexible. Truly generalizing bipartite matchings, tree assignments can be seen as such alternative matching scheme. They are particularly interesting for cell tracking, as they may capture events such as cell division, cell fusion or cells entering the scene. See Supplementary Video 4 for synthetic data displaying a simplistic simulation of a cell division tracked by ct3d.
We implemented component trees, tree-assignments and the complete cell tracking algorithm, in C++ using lp_solve 1 for solving both the tree assignment and the weighted bipartite matching (integer) linear programs, all of which is compiled in the ct3d command line tool. Cell tracking results can be further explored using at3d, which allows the user to select and extract specific cells identified by the cell tracking procedure, and derive their motility parameters such as velocity and deformation. The at3d tool is implemented using the qt framework for graphical user interfaces. Input and output of image series is designed to be compatible with other visualization software, most notably v3d (Peng et al., 2010) for producing rendered visualizations of the output.
We evaluated our algorithm on two types of data. First, we applied it to an in vivo time-lapse sequence of 3D two-photon images of zebrafish midbrain, displaying the motility of microglia; second, we applied ct3d to synthetically generated data for quantifying the accuracy of our cell tracking results.
Evalutation on in vivo data was accomplished by comparison with manually annotated trajectories of specific microglia in three datasets. Note that manual annotation is limited to trajectories, whereas boundaries of the cell volumes are almost impossible to obtain in 3D, beside systematic problems with manual annotations (Huth et al., 2010). Hence, we additionally created synthetic ground truth data to further evaluate the performance of our method. We followed the procedure used in Dufour et al. (2005), generating (noise perturbed) elliptical objects of average intensity I o above Poisson distributed background noise of intensity I b . In addition to the procedure from Dufour et al. (2005), we created perturbed images with different types of background inhomogeneities, as shown in Figure 5: in a second set of data, we introduced a multiplicative vignetting effect to the data, following the vignetting model by Kang and Weiss (2000) under different focal lengths f and off-axis illumination parameters α. In a third set of data, we introduced an additive linear gradient along the x-axis of different slopes β. Each time series consists of 20 time frames, each of size 200×200×40 pixels. On these data, we ran ct3d with size cutoffs θ min = 500 and θ max = 5000, and a single-node cutoff of 200 pixels. In the resulting sequences, all cells whose identity could be traced through the complete sequence were kept, while all other cells were discarded using the at3d tool.
Our results on the synthetically generated image sequences are summarized in Table 1 and indicate that ct3d is highly robust against different types and intensities of background inhomogeneities. The results suggest that ct3d has a tendency to identify components slightly (about 10%) larger than the actual objects, as can also be seen in the sample output in Supplementary Video 3. This is a natural consequence of pruning the component trees, where the vertex that would perfectly represent an object is unlikely to be part of the pruned tree. This effect can be reduced by smaller choice for the single-node cutoff parameter σ at the cost of higher computation time.
Running times varied between roughly 4 and 6 min, with an average of 303.42 s, for completely tracking one dataset. The (Kang and Weiss, 2000). The dashed box indicates the position of the 1D section displayed in the lower part. Right: same setting with the background perturbed by an additive linear gradient. In both instances, ct3d yields reliable tracking results (see Table 1). majority of running time was spent on constructing the component trees and computing the overlap weights (14.23 s on average per time frame), whereas each tree assignment required less than one second on average; the pruned component trees typically comprised a few dozens of vertices.
As a reference algorithm to compare against the performance ofct3d, we computed a segmentation of each time frame using the active contour approach by Chan and Vese (2001), 2 which is a wellestablished and state-of-the-art representative of the large family of level set methods. As shown in Table 1, this method works highly accurate in the absence of background inhomogeneity while getting less reliable with increasing levels of background inhomogeneity, as can be expected due to the involvement of a global background model. Figure 6 shows a result obtained from our tracking algorithm on a time series of microglia images measured as described above. We reduced resolution by half, so that the resulting width and height varied between 146 and 250 pixels, while the depth ranged between 14 and 66 layers for each time frame; each time series comprised 30-80 time frames. Gray scale resolution was reduced from 16 bit to 8 bit. We applied ct3d using parameters θ min = 200, θ max = 10 000 and a single-node cutoff of 200 pixels; the resulting pruned component trees contained 69 vertices on average, ranging between 40 and 168 vertices. Running times varied between roughly 2 and 10 min, with 471 s on average.
Under the given experimental protocol, the phenomenon of overdetection, i.e. the recognition of segments that are not microglia, is inevitable. This is due to the limited specificity of the apoE-GFP gene, which is also expressed in cells other than microglia in the surrounding tissue, often at comparably high levels as in microglia. Yet, ct3d identifies microglia as segments that can be visually distinguished from non-microglia segments by a human observer due to their characteristic shape or motion patterns. The Ct3d graphical user interface of the at3d tool (see Fig. 4) allows to manually eliminate false positive cells from tracking results by different filtering and visual selection functions similar to those provided by Celltrack for 2D time-lapse sequences. The at3d tool also allows to manually correct for the occasionally observed events of oversegmentation, i.e. one microglia being recognized as two segments. We used at3d to eliminate non-microglia from all six datasets and correct oversegmentation in individual frames. We were able to reconstruct trajectories of all relevant microglia that can be visually identified in the original datasets; only one dataset was affected by a sudden 'frameshift', i.e. the sample changing its distance to the camera in the z direction, leading to interrupted trajectories at the corresponding time frame. In few other cases, the trajectory of a microglia was interrupted in individual frames, which we could correct using at3d. Examples of the final results are given in Supplementary Videos 1 and 2.
In order to quantitatively evaluate the quality of ct3d results on in vivo microglia data, we compared ct3d trajectories with manual annotations. To this end, we selected four microglia from four different datasets and annotated their trajectories manually using the 3D polyline markup feature of the v3d software. The root mean square distance between the ct3d and the manual trajectories turned out to be 2.9 voxels, 5.5 voxels, 2.6 voxels and 5.4 voxels, respectively, in the four different datasets. These deviations can be considered relatively small in relation to the cell diameters, which were measured as 22.8, 22, 19.6 and 44.3 voxels, respectively.
We have presented a novel approach to tracking cells in 3D time-lapse microscopy image sequences, based on the concepts of component trees and cosegmentation. We demonstrate that this approach is robust against the numerous challenges imposed by images measured in an in vivo environment, and allows to identify microglia and their motion patterns in zebrafish neural tissue when combined with the at3d annotation tool. In a quantitative evaluation, we show that our approach is robust against different types of background inhomogeneities. This suggests that ct3d andat3d are potentially useful for in vivo imaging studies investigating other aspects than just microglia motility. In its current formulation, our cosegmentation approach relies on the assumption that the area occupied by an object overlaps between two consecutive time points. While this may not be satisfied in all cell tracking problems [e.g. when tracking centrosomes (Jaensch et al., 2010)], it is a reasonable assumption for many immunoimaging-related studies.
To the best of our knowledge, our approach is the first that can identify and track microglia in live cell imaging time series. In most cases, obtaining reliable trajectories still requires manual post-processing of the output. The most notorious difficulties certainly are the complex morphology-their deformation patterns, irregular shapes and interaction with the surrounding-as well as the unspecificity of the fluorescent markers available. In this light, our approach constitutes significant progress in the sense that it has sufficient sensitivity to separate microglia form their surrounding. Yet, a fully automated approach remains a major and certainly non-trivial challenge. A first step in this direction might be the combination with level-set based approaches as utilized for 2D cellBottom: quantitative comparison of trajectories obtained by ct3d and the active contour approach from Chan and Vese (2001). In general, ct3d could identify the annotated cells in all time frames (columns # Frames). The root mean square distance to the annotated trajectory measures a fraction of the diameter of the annotated cell (columns cell and RMS), while the Chan-Vese algorithm missed varying numbers of cells or failed completely (last column). For the Chan-Vese results, a parameter set was optimized for dataset (a). This parameter set (µ = 1, ν = .5, λ 1 = .2, λ 2 = 5) was also applied to datasets (b) to (d). While for dataset (a), the result is comparable to ct3d, the annotated cell was identified in only 29 out of 49 time frames in (b). In datasets (c) and (d), the annotated cell could not be identified at all using these parameters. See Supplementary Figure tracking by Nath et al. (2006) that might yield more accurate cell boundaries in some cases. Yet, ct3d promises to be a key tool for further studying open questions regarding microglia, such as to determine if and how glia and microglia share the task of finding and removing apoptotic neurons from the vertebrate brain (Peri and Nüsslein-Volhard, 2008).
