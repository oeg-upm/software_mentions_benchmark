
(1) Finding intervals I1 . . . I, that each contains a minimum; (2) Iteratively approaching for each j = 1 . . . n the minimum contained in the interval Ij until a defined precision is reached, yielding a candidate value aj for the minimum in Ij; (3) Calculating the error values errj = errneo(aj) for each candidate and selecting aj that corresponds to the minimal error amongst err1 . . . errn. The algorithm is implemented in Java in the framework of the ace.map suite for microarray statistical data analysis, which will be described in detail elsewhere.
Applied Biosystems Expression Array System Soft- ware (V1.l.l, ProdNo: 4364137) has been used to acquire the CL and fluorescence (FL) images and primary data analysis. Briefly, the primary analysis consists of the following individual operations: (1) Image correction; (2) Global and local background correctton; (3) Feature normalization; (4) Spatial normalization; (5) Global normalization. Note that we renormalize the resulting data according to the median once more after having removed probes for which the Applied Biosystems Software has set flags greater than 212, indicating compromised or failed measurements (as recommended by Applied Biosystems). This secondary normalization is implemented in the ace.map suite.
The routine is implemented in Java using the supplied pseudo random number generator and the transformation function Ijava.util.Random.next The two generated artificial datasets differ by the ratio f, the mean p, and the variance B . The first dataset shown in Figure 5B was generated at constant a=O.l*p for all combinations of f=l/16, l/s, 114 and p=0.5, 1.0, 1.5. The second dataset discussed in Tables 1 and 2 was generated with constant constant B = p, and varying f=l/256 to 1/4. Simply, the first dataset creates ever larger perturbations (with increasing f ) at ever larger distance to a=O (with increasing p ) with a constant and small variance of the perturbation. The second dataset creates exponentially increasing perturbations (with increasing f ) at a constant distance to a=O with a constant and large variance.
(1) Median normalization, linear. Assuming symmetry in the fold change; after calculating the fold changes, the median is subtracted from the log2-transformed signal quotients. (2) LOWESS normalization, non-linear. LOWESS is a method developed by Cleveland (33) in 1979 and since then has been frequently improved and modified. It was a p plied to microarray data analysis for the first time by Yang et al ( 1 1 ) in 2001. For the original method, four parameters have to be specified (which normally happens more or less arbitrarily), and changes in each of them lead to different results. A suggestion for optimized parameter selection was published by Berger et a1 ( 1 2 ) in 2004. LOWESS performs very well for poorly preprocessed data. The LOWESS implementation used to compare to NeONORM is a Java port of Cleveland's original FORTRAN code from 1985 freely available (http://netlib.belllabs.com/netlib/go/lowess.f.gz), which was temporarily embedded in the ace.map platform for direct comparative testing.
Histograms and frequency plots appearing in the figures were generated using ace.map, however, are standard means of data representation. The 3Dsurface plots in Figure 4 were rendered using gnupplot 4.0. Sign plots (blue = negative, red = positive) were rendered by an ace.map plug-in. Subtraction profiles consist of logs-transformed quotients (logQ) of signal intensities for the intersection set of the probe IDS, which were contained in the two input sample files used for the subtraction.
