
with an already present receiving hand. The conditions were love (hands caressing), pain (one hand hitting the other), social exclusion (one hand pushing away the other friendly hand), and neutral videos (approaching hand touching the other and getting a non-emotional response). A duplicate of every video was left-right mirrored (Adobe Premiere) to ensure that hands entered equally often from both sides. Subjects were instructed to watch the videos as if they were watching one of their favourite videos. They were told that a question would be asked later and that they could answer it if they had watched (not memorized) the videos carefully. Two event-related runs ($8 min) consisted of 36 videos (nine instances of each condition), separated by a fixation cross for 8-12 s Fig. 1C). Subjects' left eye-gaze was recorded by an infrared camera (SMI, iView; 50 Hz).
Images were analysed with SPM5 (http://www.fil.ion.ucl.ac.uk/ spm/software/spm5). For each subject, echo planar images were aligned to each other; the T 1 co-registered to the mean echo planar image and normalization parameters (obtained from T 1 segmentation) applied to all echo planar images (3 Â 3 Â 3 mm resolution), followed by smoothing (9 mm Gaussian kernel). Echo planar images were highpass filtered at 300 s. A separate general linear model was used for each experiment.
(i) We selected studies and meta-analyses that included an experience and an observation condition of actions, sensations or emotions and selected the regions most consistently activated by experience and observation. Whenever possible we then used the Anatomy ToolBox (Eickhoff et al., 2007) or the AAL atlas of the WFU Pickatlas (Maldjian et al., 2003) for regions not yet included in the Anatomy ToolBox and then combined them into a single composite anatomical region of interest using a logical 'OR' (Fig. 2, blue transparent regions). These anatomical regions, defined using Anatomy ToolBox included the premotor cortices (Brodmann area 6 in Anatomy ToolBox) (Gazzola and Keysers, 2009; Caspers et al., 2010), the primary and secondary somatosensory cortices (SI = BA3a + b + BA1 + BA2 and SII = OP1 + OP2 + OP3 + OP4) (Keysers et al., 2010). Those defined using the AAL included the insula and the anterior/mid cingulate (Wicker et al., 2003; Singer et al., 2004, 2006; Jabbi et al., 2007; Bastiaansen et al., 2009; Lamm et al., 2011). (ii) We used the results from our localizer experiment (i.e. experience) to select voxels that were significantly activated by at least one of our stimuli by either one of the groups (Fig. 2, red transparent regions). Eight one-sample random effect t-tests, comparing the four summary volumes (love, pain, neutral, exclusion) of the controls and those of the patients against zero (P unc 5 0.001), were combined by a logical 'OR' (Marsbar;http://marsbar.sourceforge.net/) to generate a composite functional region of interest. We combined all hand interactions into a single region of interest, because empathic responses in the viewer are not always equal to the emotion in the actor; seeing pain can trigger tender feelings in addition to, or instead of, pain. Using a composite functional region of interest that included voxels triggered by any of the experiences (love, pain, exclusion or neutral), ensured an inclusive analysis that also captured empathic responses that are not equal to the viewed emotions: tender feelings triggered by a pain video would be captured by such a composite functional region of interest, because similar tender feelings will have been triggered by the love interactions also included in the region of interest definition. The same holds for pain triggered by the sight of exclusion etc. (iii) A logical 'AND' was used to combine the composite functional and anatomical regions of interest (Fig. 2, purple transparent regions) leading to our final region of interest.
